{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Cleaning in Pandas\n",
    "\n",
    "![](https://media.giphy.com/media/AhAysobj49aqQ/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning goals: To apply pandas data cleaning methods to animal shelter data.\n",
    "![austin](http://www.austintexas.gov/sites/default/files/aac_logo.jpg)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda:\n",
    "- Understand why data cleaning is important\n",
    "- Review ways to read data into a pandas dataframe\n",
    "- Apply pandas methods to inspect our data\n",
    "- Clean our data using pandas methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is data cleaning important and how does it fit into the data science process?\n",
    "\n",
    "Remember this CRISP-DM Model?\n",
    "\n",
    "<img src='https://storage.ning.com/topology/rest/1.0/file/get/2808314343?profile=RESIZE_480x480' width='500'>\n",
    "\n",
    "#### ACTIVITY\n",
    "\n",
    "With your group, read [this article](https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt?utm_campaign=Data_Elixir&utm_source=Data_Elixir_303) (focus on the sections \"Data Cleaning IS Analysis\" through \"Cleaning your data allows you to know your data\" and disucuss:\n",
    "\n",
    "- Why is data cleaning important?\n",
    "- What questions should you be thinking about as your clean your data?\n",
    "- How can data cleaning help you in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the [Austin Animal Shelter](http://www.austintexas.gov/department/aac) is hosted in these locations:\n",
    "\n",
    "**Intakes**:\n",
    "https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm <br>\n",
    "**Outcomes**: https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238\n",
    "\n",
    "We will read it into our notebook using [pd.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = pd.read_csv('./data/Austin_Animal_Center_Outcomes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's do the same for intakes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intakes = pd.read_csv('./data/Austin_Animal_Center_Intakes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect data\n",
    "#### Check top and bottom of dataset\n",
    "\n",
    "We can use the `.head()` method to view the first few rows of our dataframe.  \n",
    "\n",
    "Note: by default the function returns the first 5 rows but you can view more or less by specifying the number of rows you want to view inside the () like this `.head(20)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can view the bottom of our dataframe by using the `.tail()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that we know it's a `DataFrame` because now, given the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), we can always expect answers on any dataset we load in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What's the length and width of our dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.shape` attribute tells us how many rows and columns in our dataframe. Our outcomes dataset has 108,519 rows and 12 columns of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:  What does a row of data represent in this dataset?  What are some things we should consider when we are performing analysis on this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Get column names\n",
    "\n",
    "We might also want to examine just the names of each column in our dataframe.  We can do this by using the `.columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Columns** in a dataframe on an individual level are `Series` objects <br>\n",
    "To access an individual column, the easiest way to to use `.` notation:<br>\n",
    "`outcomes.Name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your column name has spaces in it the `.` notation will not work but you can use `[]` to access those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['Outcome Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Check data type of each column\n",
    "Type of the data (integer, float, Python object, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Get data type *and* an idea of how many missing values\n",
    "Which columns have missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative we can look at the sum of all missing values by chaining the `.isna()` function which is a boolean with the `.sum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Your Turn!\n",
    "\n",
    "### Apply to `intakes`\n",
    "\n",
    "Now, for the `intakes` dataset. How does it compare to `outcomes`?\n",
    "- does it have the same number of observations?\n",
    "- same column  names?\n",
    "- do rows in data represent the same level of information?\n",
    "- are the datatypes the same or different?\n",
    "- what about missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now let's find the age of the animals in the shelter!\n",
    "\n",
    "#### This should be easy, we have 'Age upon Outcome' in our outcomes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['Age upon Outcome'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wait! Something went wrong!\n",
    "What happened? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are going to need to struggle through some data cleaning\n",
    "\n",
    "![panda struggle](img/panda_struggle.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First step**: make the column names easier to work with\n",
    "\n",
    "Going to use `str`, `lower`, and [`replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html) to make our lives easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.columns = outcomes.columns.str.lower()\n",
    "outcomes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.columns = outcomes.columns.str.replace(' ', '_')\n",
    "outcomes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Your Turn!\n",
    "\n",
    "#### Apply the above cleaning to intakes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **Why** care about that?\n",
    "Because now I can use `tab` to find column names.<br>\n",
    "\n",
    "#### How many of each type of animals are in the outcomes dataset?\n",
    "\n",
    "We can use the [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) function to get counts for each value in the animal types column in outcomes.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.animal_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's see the unique values of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.age_upon_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What's the challenge with these numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### What could we use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Steps needed:\n",
    "- convert dates to correct date types\n",
    "- create a new age variable subtracting dates\n",
    "- drop the original age variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Converting dtypes\n",
    "\n",
    "Okay, going to use a [`apply`](https://pandas.pydata.org/pandas-docs/version/0.18/generated/pandas.Series.apply.html) and a [`lambda`](https://www.w3schools.com/python/python_lambda.asp) function. \n",
    "\n",
    "\n",
    "\n",
    "It's getting exciting, now!\n",
    "\n",
    "\n",
    "`apply`, `map`, and `applymap`\n",
    "<img src='https://miro.medium.com/max/1796/1*deCRAl5DuNZ1a0TNGKYrNQ.png' width='500'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anonymous Functions (Lambda Abstraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple functions can be defined right in the function call. This is called 'lambda abstraction'; the function thus defined has no name and hence is \"anonymous\".\n",
    "\n",
    "It looks like the `datetime` column contains the date and time the outcome occured. Let's create a new column called `date_o` where we copy the `datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['date_o'] = outcomes.datetime\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great we added that new column!  But we don't really care about the time of day the outcome occured.  We only care about the date!  Let's use a lambda function to slice that datetime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['date_o'] = outcomes.date_o.apply(lambda x: x[:10])\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!  We shortened the date.  But it's still being read as an object datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using [`to_datetime`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) we can convert this to a datetime format where we can then calculate the age of the animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date formats\n",
    "outcomes['date_o'] =  pd.to_datetime(outcomes['date_o'], format='%m/%d/%Y')\n",
    "outcomes['dob'] =  pd.to_datetime(outcomes['date_of_birth'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check to see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We did it!<br>\n",
    "Let's [`drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) the variables we will no longer use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = outcomes.drop(columns=['datetime', 'date_of_birth'] )\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Make new variable of age and years_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['age'] = outcomes.date_o - outcomes.dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['years_old'] = outcomes.age.apply(lambda x: x.days/365)\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NOW try `mean`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.years_old.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Great!  What does this mean?  What question about the data have we answered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filtering and sub-setting\n",
    "\n",
    "What if we want to see the mean age of each type of animal in the shelter?  How would we do that?\n",
    "\n",
    "\n",
    "We can use a [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function to help us aggregate and filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes[['animal_type', 'years_old']].groupby(['animal_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn! \n",
    "\n",
    "With your group, convert `datetime`to a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing values\n",
    "\n",
    "We saw earlier that we have some missing values in several columns.  Now we need to decide what to do about them.  One option is to __fill__ in the missing value and another option is to __drop__ that missing value.\n",
    "\n",
    "### Activity\n",
    "\n",
    "In your group, discuss the pros and cons of filling the missing values vs dropping the missing values for the following columns of our dataframe.\n",
    "\n",
    "- `name`\n",
    "- `outcome_type`\n",
    "- `outcome_subtype`\n",
    "- `sex_upon_outcome`\n",
    "- `age_upon_outcome`\n",
    "\n",
    "For columns in which you feel like it is important to fill the missing data what do you think we should fill these values with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Dropping rows with missing data\n",
    "Because there are very few (only 3 of the 108,519) rows of data that are missing the `sex_upon_outcome` variable we can drop the rows where this variable is missing and we will only lose less than 1% of that data.  Let's go ahead and drop these rows. \n",
    "\n",
    "We will use the `dropna` function to execute this drop. Note:  We will need to use the `subset=` argument to drop missing values in this column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = outcomes.dropna(subset=['sex_upon_outcome'])\n",
    "outcomes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing data\n",
    "\n",
    "Now let's talk about the missing values for name.  If we dropped all these rows we would lose about 32% of our data!  That's a lot! Plus, maybe we want to examine how many of the animals in the shelter don't have names.  Then we would need this information! So instead of dropping those rows let's replace missing names with the string \"No name given\".\n",
    "\n",
    "We can use the `.fillna` function to fill in those missing values with our desired string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['name'] = outcomes.name.fillna(\"No name given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great!  We have successfully cleaned up two of columns with missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "In your group, work on cleaning the `outcome_subtype` column and the `age_upon_outcome` column.  Be thoughtful in how you deal with these missing values.  Be able to explain why you made the decisions you did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now we are rolling!!\n",
    "\n",
    "![panda roll](img/panda_rolling.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Further Resources\n",
    "- Learn from [Wes McKinney himself](https://www.youtube.com/watch?v=_T8LGqJtuGc#action=share) in his \"Pandas in 10 minutes video\"\n",
    "- Make the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) your best friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
